{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/gEuH04ti5NXWGRU0laNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mumnsa/DAC-Curriculum-2025/blob/main/Student_Copy_EDA_DAC_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRODUCTION**\n",
        "\n",
        "***What is Exploratory Data Analysis ?***\n",
        "- understanding the data sets by summarizing their main characteristics\n",
        "- often plotting them visually\n",
        "- This step is very important especially when we arrive at modeling the data in order to apply MACHINE LEARNING.\n",
        "- Plotting in EDA consists of Histograms, Box plot, Scatter plot and many more. It often takes much time to explore the data.\n",
        "\n",
        "Through the process of EDA, we can ask to define the problem statement or definition on our data set which is very important.\n",
        "\n",
        "***What data are we exploring today ?***\n",
        "\n",
        "We will start off our EDA journey with a simple data set regarding a specific store's coffee sales. This dataset includes Date, Time, Payment method, Type of Coffee Sold, and Money Earned.\n",
        "\n",
        "**1 . IMPORTING LIBRARIES**\n",
        "\n",
        "***WHAT are Libraries & WHY do we need them?***\n",
        "\n",
        "- Libraries in programming are pre-written collections of code.\n",
        "- They provide useful functions, classes, and modules that can be reused in your own code.\n",
        "- Libraries act as toolkits or packages to avoid rewriting common functionality.\n",
        "- They help you avoid reinventing the wheel by offering ready-made solutions for common tasks.\n",
        "\n",
        "Libraries can be compared to recipe books in cooking: Instead of baking a cake from scratch, you can follow a well-known recipe (i.e., pre-written code).\n",
        "\n",
        "In summary, libraries are essential because they help us work faster, ensure our code is reliable, and allow us to tackle more complex problems easily by using tools that others have already built and perfected!\n",
        "\n",
        "**How to install :**\n",
        "NOTE : for macOS use pip3 , for Windows use pip\n",
        "\n",
        "COMMAND : \" !pip\n",
        " install pandas \""
      ],
      "metadata": {
        "id": "NbuKrwyqiZnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example\n",
        "# Install packages first in order to be able to install libraries\n",
        "!pip3 install pandas"
      ],
      "metadata": {
        "id": "EuJ-mspMjmEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You will now be able to import required libraries.\n",
        "import pandas as pd         # data manipulation & analysis\n",
        "import numpy as np          # numerical & mathematical operations\n",
        "import matplotlib.pyplot as plt         # for creating visualisations\n",
        "import seaborn as  sns          # for more advanced visualisations"
      ],
      "metadata": {
        "id": "0bDiRCn1j8Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hereâ€™s a simple explanation of the purpose of each import statement:**\n",
        "\n",
        "***1. import pandas as pd***\n",
        "- **Purpose:** Loads the **pandas** library, which is used for data manipulation and analysis.\n",
        "- **What it does:** It allows you to work with data in tables, similar to Excel, called DataFrames, and to perform operations like filtering, grouping, and merging data.\n",
        "\n",
        "***2. import numpy as np***\n",
        "- **Purpose:** Loads the **NumPy** library, which is essential for numerical and mathematical operations.\n",
        "- **What it does:** It helps with handling arrays (lists of numbers) and performing calculations like averages, sums, and matrix operations.\n",
        "\n",
        "***3. import matplotlib.pyplot as plt***\n",
        "- **Purpose:** Loads **matplotlib**, a library for creating visualizations.\n",
        "- **What it does:** It helps in making basic plots like line charts, bar charts, and scatter plots.\n",
        "\n",
        "4. import seaborn as sns\n",
        "- **Purpose:** Loads Seaborn, a data visualization library built on top of matplotlib.\n",
        "- **What it does:** It makes it easier to create more advanced and visually appealing statistical plots, like heatmaps, box plots, and violin plots."
      ],
      "metadata": {
        "id": "ub90zG4-kDs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. LOADING THE DATA into a DATAFRAME using pandas**\n",
        "\n",
        "**How this works :** You can use pandas to read your data file, and organise them into a Dataframe (made up of ROWS & COLUMNS).\n",
        "- can read CSV, Excel, SQL etc\n",
        "\n",
        "What is A CSV?\n",
        "- CSV is a Comma-Separated Values text file where each line of the file represents a row of data, and the values within a row are separated by commas.\n",
        "- other forms of text files are : Tab-Separated Values (tsv), Semicolon-Separated Values (ssv)"
      ],
      "metadata": {
        "id": "Q3_eiYmuloOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Place Coffee_Sales.csv into a google drive folder and remember where you have kept it\n",
        "# Import and mount csv into google colab notebook (you will be required to sign in into your google account)\n"
      ],
      "metadata": {
        "id": "vaZglXyFl--9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that it is mounted, we can access it via the file path (different for everyone, use your file path)\n"
      ],
      "metadata": {
        "id": "941WTGGIoIvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**3. VIEWING THE DATA'S CONTENTS**"
      ],
      "metadata": {
        "id": "898AedQ9oTvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To view FIRST 5 rows"
      ],
      "metadata": {
        "id": "6DtN-WAloXFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view LAST 5 rows"
      ],
      "metadata": {
        "id": "NakxOE4modWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view the unique elements in cash_type (we can call it payment method)"
      ],
      "metadata": {
        "id": "ckJGoB5JogGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To find out number of payments by cash or card"
      ],
      "metadata": {
        "id": "sgQ0EZeEpWLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. VIEWING THE DATA'S GENERAL INFO & STATS**\n"
      ],
      "metadata": {
        "id": "IigI4m4spfzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It will return the (number of rows, number of columns)"
      ],
      "metadata": {
        "id": "lzxgH4FapmqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It will print all the column names ofour dataset"
      ],
      "metadata": {
        "id": "K5N1T_8Kptqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.dtypes shows the types of data in our Dataframe"
      ],
      "metadata": {
        "id": "c_Ye1o0ZpyNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.info() shows a summary of our data set"
      ],
      "metadata": {
        "id": "_hKu9l5vcFhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show_counts=True hows number of non-null rows\n",
        "# will notice that card only has 1660 non-null rows -> we need te remove!"
      ],
      "metadata": {
        "id": "fpYCdMZkcRrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**int64** : This data type is used to **represent integer values**. The int64 type indicates that each element in the column is a 64-bit integer.\n",
        "\n",
        "**float64** : This data type is used to represent floating-point values, which are **numbers that can have decimal places**. The float64 type indicates that each element in the column is a 64-bit floating-point number.\n",
        "\n",
        "**object** : This data type is a catch-all for columns that contain mixed types or are not easily classified as numerical. Columns with the data type object can **contain strings, mixed types, or even Python objects**."
      ],
      "metadata": {
        "id": "Yw-Pfka4caIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying a STATISTICAL summary of our data in 5dp\n",
        "# (only for columns with numerical values)\n",
        "pd.options.display.float_format = '{:.5f}'.format\n",
        "df.describe()\n",
        "# .describe() is a function in pandas that shows the statistical summary of our dataset"
      ],
      "metadata": {
        "id": "d6HWwNyIcmoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. CLEANING THE DATA**\n",
        "\n",
        "**NULL DATA**\n",
        "\n",
        "\n",
        "\n",
        "*   for this dataset, we will not remove null rows first.\n",
        "\n"
      ],
      "metadata": {
        "id": "ha6x2biucstN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View the number of null rows according to its column names\n",
        "# Remove all rows with a null values in them\n",
        "# axis = 0 ==> rows\n",
        "# axis = 1 ==> columns\n",
        "\n",
        "## df = df.dropna()\n",
        "\n",
        "# then you will notice now your dataframe has only 1660 rows instead of the initial 1748 rows."
      ],
      "metadata": {
        "id": "aHs8CcMwc_HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the same command, now we notice there are no more null rows!"
      ],
      "metadata": {
        "id": "gbyxdW6vjU0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## df.count()\n",
        "# number or rows are all now 1660"
      ],
      "metadata": {
        "id": "_UXAzDHYjXOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**DUPLICATED DATA**"
      ],
      "metadata": {
        "id": "LI_OMQK0jZIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows_df = df[df.duplicated()]\n",
        "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
      ],
      "metadata": {
        "id": "aKg-Ve65jbWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this case, there are no duplicated rows\n",
        "\n",
        "It is showing two numbers:\n",
        "\n",
        "0: The number of duplicate rows found.\n",
        "\n",
        "6: The number of columns in the DataFrame."
      ],
      "metadata": {
        "id": "Sh8X3-2mjfOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if there are duplicated rows, we use\n",
        "# df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "Ha-VaZX9jg3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. EXPLORE OUR DATA !**"
      ],
      "metadata": {
        "id": "owwLQg8pjnQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting ['date'] into date-time format => more uniform data => easier plotting => better analysis\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])"
      ],
      "metadata": {
        "id": "zTq01gHejpXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Commonly used functions!**\n",
        "\n",
        "**df['date']:**\n",
        "\n",
        "* This accesses the 'date' column from the\n",
        "DataFrame df, which contains the dates of the sales transactions\n",
        "\n",
        "**value_counts():**\n",
        "\n",
        "* This function counts the occurrence of each unique date, effectively calculating how many sales occurred on each date. The result is a Series where the index represents the dates and the values represent the sales count.\n",
        "\n",
        "**sort_index():**\n",
        "\n",
        "* The output of value_counts() is sorted by date (index) to ensure the sales data is ordered chronologically, so the line chart reflects the correct time sequence.\n",
        "\n",
        "**plot(kind='line', title='Daily Coffee Sales'):**\n",
        "\n",
        "* This plots the sales count (values) against the dates (index) as a line plot, with the title \"Daily Coffee Sales\".\n",
        "\n",
        "* The kind='line' specifies that a line chart should be used.\n",
        "\n",
        "* you can choose to use 'bar', 'box', 'hist', 'pie'\n",
        "\n",
        "**plt.rcParams['figure.figsize'] = (14, 6):**\n",
        "\n",
        "* This configures the default size of the plot, making it 14 units wide and 6 units tall. This ensures that the chart is large enough for clear visualization."
      ],
      "metadata": {
        "id": "3nY0yJl7jtT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To check daily sales across March 2024 to November 2024"
      ],
      "metadata": {
        "id": "vF4UQNbulW3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TO ADD COLOURS TO VISUALISATIONS :**\n",
        "\n",
        "* MatplotLib - use colors = ' '\n",
        "* Seaborn - use palette = ' '"
      ],
      "metadata": {
        "id": "MPX6tzkald06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# you can play around with the colours!\n",
        "\n",
        "\n",
        "# for this, if null rows are removed we have no more cash!!!"
      ],
      "metadata": {
        "id": "dHILj-mGljNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which day of the week has the highest sales?\n",
        "# 0=Monday, 6=Sunday\n",
        "df['weekday'] = df['date'].dt.weekday\n",
        "plt.rcParams['figure.figsize'] = (14,6)\n",
        "\n",
        "df['weekday'].value_counts().sort_index().plot(kind='bar', title='Sales by Weekday', color='pink')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XvrFDhBWlnOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which hour has the highest coffee sales?\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "df['hour'].value_counts().sort_index().plot(kind='bar', title='Sales by Hour of Day', color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ufy7KWTOlqxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot: To check for outliers in the sale amounts.\n",
        "sns.boxplot(x=df['money'])\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.title('Sale Amount Boxplot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HB8gqdG9lsL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which coffee is the most popular?\n",
        "df['coffee_name'].value_counts().plot(kind='bar', title='Top-Selling Coffee Types')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "plt.xticks(rotation=45)  #adjust words on x axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bx_j-4mwltez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Coffee_Popularity = sns.countplot(x = 'coffee_name', data = df, palette = 'colorblind')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "for bars in Coffee_Popularity.containers:\n",
        "    Coffee_Popularity.bar_label(bars)\n",
        "\n",
        "    plt.xticks(rotation=45)"
      ],
      "metadata": {
        "id": "pm95ZwXzlusD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Coffee_Sales = df.groupby(['coffee_name'], as_index = False)['money'].sum().sort_values(by = 'money', ascending = False)\n",
        "sns.barplot(x = 'coffee_name', y = 'money', data  = Coffee_Sales, palette = 'Blues')"
      ],
      "metadata": {
        "id": "aO2k160Nlwcu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}